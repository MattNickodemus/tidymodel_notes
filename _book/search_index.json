[["index.html", "My tidymodels notes Chapter 1 Disclaimer", " My tidymodels notes Matt Nickodemus 2021-01-17 Chapter 1 Disclaimer These are my notes on the tidymodels meta-package. The thoughts, code, drawings, and notes are copied from several other sources, so nothing here should be attributed to me. This is just my notebook where I collect things I like as I learn. "],["sources.html", "Chapter 2 Sources", " Chapter 2 Sources The tidymodels webpage managed by RStudio. https://www.tidymodels.org/ The tidymodels book https://www.tmwr.org/ This is a good little book on data science and tidymodels. It is pretty up to date. The only issue I have is that they use Jupyter notebooks. I might want to look into trying that, though. https://ubc-dsci.github.io/introduction-to-datascience/ "],["clustering.html", "Chapter 3 Clustering 3.1 Quick description 3.2 In pictures 3.3 In R", " Chapter 3 Clustering These are my notes from the tutorial on k-means clustering in the tidymodels framework. The code comes from RStudio. The RStudio website also has some really nice pictures by Allison Horst for this process so I stole those as well. 3.1 Quick description How does this algorithm work? We start with a random set of two dimensional data points. Assume we want to group this data into three classes. Begin by randomly guessing where the centroid of each of the three sets is. Then classify each point as belonging to the class of the centroid nearest it. Next recalculate the centroid for each cluster. Again classify each point based on it’s nearest centroid, then recalculate the centroid. Repeat. 3.2 In pictures Thank you to Allison Horst for drawing these. 3.3 In R To see how this looks in R, load the tidymodels libraries. library(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.2 ── ## ✓ broom 0.7.3 ✓ recipes 0.1.15 ## ✓ dials 0.0.9 ✓ rsample 0.0.8 ## ✓ dplyr 1.0.2 ✓ tibble 3.0.4 ## ✓ ggplot2 3.3.2 ✓ tidyr 1.1.2 ## ✓ infer 0.5.3 ✓ tune 0.1.2 ## ✓ modeldata 0.1.0 ✓ workflows 0.2.1 ## ✓ parsnip 0.1.4 ✓ yardstick 0.0.7 ## ✓ purrr 0.3.4 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## x purrr::discard() masks scales::discard() ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() ## x recipes::step() masks stats::step() Create the fake data. We will have three clusters. set.seed(27) centers &lt;- tibble( cluster = factor(1:3), num_points = c(100, 150, 50), # number points in each cluster x1 = c(5, 0, -3), # x1 coordinate of cluster center x2 = c(-1, 1, -2) # x2 coordinate of cluster center ) Now generate the points. This is a great trick here where we apply the rnorm function using {purr} to create a nested data frame. We then drop the input (num_points) that we used to generate the data, unnest, and viola, a data frame with data labeled in clusters. I like this a lot. labelled_points &lt;- centers %&gt;% mutate( x1 = map2(num_points, x1, rnorm), x2 = map2(num_points, x2, rnorm) ) %&gt;% select(-num_points) %&gt;% unnest(cols = c(x1, x2)) ggplot(labelled_points, aes(x1, x2, color = cluster)) + geom_point(alpha = 0.3) points &lt;- labelled_points %&gt;% select(-cluster) kclust &lt;- kmeans(points, centers = 3) kclust ## K-means clustering with 3 clusters of sizes 148, 51, 101 ## ## Cluster means: ## x1 x2 ## 1 0.08853475 1.045461 ## 2 -3.14292460 -2.000043 ## 3 5.00401249 -1.045811 ## ## Clustering vector: ## [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [38] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [75] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 ## [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 ## [260] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## [297] 2 2 2 2 ## ## Within cluster sum of squares by cluster: ## [1] 298.9415 108.8112 243.2092 ## (between_SS / total_SS = 82.5 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; ## [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; "]]
